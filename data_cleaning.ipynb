{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading dataset:\n",
    "We expect dataset to be present at datasets folder. For getting the dataset from kaggle, we execute the data_fetchong.ipynb file. It extracts and stores the CSVs in datasets directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 731290 entries, 0 to 731289\n",
      "Data columns (total 16 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   Mal ID            731290 non-null  int64  \n",
      " 1   Username          731289 non-null  object \n",
      " 2   Gender            224383 non-null  object \n",
      " 3   Birthday          168068 non-null  object \n",
      " 4   Location          152805 non-null  object \n",
      " 5   Joined            731290 non-null  object \n",
      " 6   Days Watched      731282 non-null  float64\n",
      " 7   Mean Score        731282 non-null  float64\n",
      " 8   Watching          731282 non-null  float64\n",
      " 9   Completed         731282 non-null  float64\n",
      " 10  On Hold           731282 non-null  float64\n",
      " 11  Dropped           731282 non-null  float64\n",
      " 12  Plan to Watch     731282 non-null  float64\n",
      " 13  Total Entries     731282 non-null  float64\n",
      " 14  Rewatched         731282 non-null  float64\n",
      " 15  Episodes Watched  731282 non-null  float64\n",
      "dtypes: float64(10), int64(1), object(5)\n",
      "memory usage: 89.3+ MB\n"
     ]
    }
   ],
   "source": [
    "users_df = pd.read_csv(\"datasets/users-details-2023.csv\")\n",
    "users_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24905 entries, 0 to 24904\n",
      "Data columns (total 24 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   anime_id      24905 non-null  int64 \n",
      " 1   Name          24905 non-null  object\n",
      " 2   English name  24905 non-null  object\n",
      " 3   Other name    24905 non-null  object\n",
      " 4   Score         24905 non-null  object\n",
      " 5   Genres        24905 non-null  object\n",
      " 6   Synopsis      24905 non-null  object\n",
      " 7   Type          24905 non-null  object\n",
      " 8   Episodes      24905 non-null  object\n",
      " 9   Aired         24905 non-null  object\n",
      " 10  Premiered     24905 non-null  object\n",
      " 11  Status        24905 non-null  object\n",
      " 12  Producers     24905 non-null  object\n",
      " 13  Licensors     24905 non-null  object\n",
      " 14  Studios       24905 non-null  object\n",
      " 15  Source        24905 non-null  object\n",
      " 16  Duration      24905 non-null  object\n",
      " 17  Rating        24905 non-null  object\n",
      " 18  Rank          24905 non-null  object\n",
      " 19  Popularity    24905 non-null  int64 \n",
      " 20  Favorites     24905 non-null  int64 \n",
      " 21  Scored By     24905 non-null  object\n",
      " 22  Members       24905 non-null  int64 \n",
      " 23  Image URL     24905 non-null  object\n",
      "dtypes: int64(4), object(20)\n",
      "memory usage: 4.6+ MB\n"
     ]
    }
   ],
   "source": [
    "anime_df = pd.read_csv('datasets/anime-dataset-2023.csv')\n",
    "anime_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24325191 entries, 0 to 24325190\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Dtype \n",
      "---  ------       ----- \n",
      " 0   user_id      int64 \n",
      " 1   Username     object\n",
      " 2   anime_id     int64 \n",
      " 3   Anime Title  object\n",
      " 4   rating       int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 927.9+ MB\n"
     ]
    }
   ],
   "source": [
    "user_score_df = pd.read_csv('datasets/users-score-2023.csv')\n",
    "user_score_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning Users Details dataset for Joining Date and Birthday\n",
    "1. Cleaning joining date. Steps followed for these are:\n",
    "    -   Remove rows where the value is NaN\n",
    "    -  Remove time strings from date strings\n",
    "    - Convert Date strings to pandas datetime object\n",
    "2. Cleaning birthdate. Steps followed for these are:\n",
    "    - Remove rows where the value is NaN\n",
    "    - Remove time strings from date strings\n",
    "    - Convert Date strings to pandas datetime object\n",
    "    - Remove entries where birthdate is very very old, ie before 1950-01-01\n",
    "3. Cleaning entries based on relation between joining date and birthdate\n",
    "    - Remove entries where joining date is older than birthdate\n",
    "    - Remove entries where age at joining is less than 5 years.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Birthday_Date</th>\n",
       "      <th>Joined_Date</th>\n",
       "      <th>Age_Join</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>644052</th>\n",
       "      <td>2006-12-24</td>\n",
       "      <td>2011-12-22</td>\n",
       "      <td>5.010989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689583</th>\n",
       "      <td>2007-03-07</td>\n",
       "      <td>2012-03-06</td>\n",
       "      <td>5.016484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298281</th>\n",
       "      <td>2005-07-16</td>\n",
       "      <td>2010-07-16</td>\n",
       "      <td>5.016484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164355</th>\n",
       "      <td>2004-04-12</td>\n",
       "      <td>2009-04-29</td>\n",
       "      <td>5.063187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22741</th>\n",
       "      <td>2002-10-07</td>\n",
       "      <td>2007-11-29</td>\n",
       "      <td>5.162088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652659</th>\n",
       "      <td>1950-08-22</td>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>61.576923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444033</th>\n",
       "      <td>1950-02-20</td>\n",
       "      <td>2011-07-05</td>\n",
       "      <td>61.579670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717227</th>\n",
       "      <td>1950-11-14</td>\n",
       "      <td>2012-04-04</td>\n",
       "      <td>61.598901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668048</th>\n",
       "      <td>1950-03-23</td>\n",
       "      <td>2012-01-25</td>\n",
       "      <td>62.054945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715537</th>\n",
       "      <td>1950-04-25</td>\n",
       "      <td>2012-04-02</td>\n",
       "      <td>62.151099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166200 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Birthday_Date Joined_Date   Age_Join\n",
       "644052    2006-12-24  2011-12-22   5.010989\n",
       "689583    2007-03-07  2012-03-06   5.016484\n",
       "298281    2005-07-16  2010-07-16   5.016484\n",
       "164355    2004-04-12  2009-04-29   5.063187\n",
       "22741     2002-10-07  2007-11-29   5.162088\n",
       "...              ...         ...        ...\n",
       "652659    1950-08-22  2012-01-03  61.576923\n",
       "444033    1950-02-20  2011-07-05  61.579670\n",
       "717227    1950-11-14  2012-04-04  61.598901\n",
       "668048    1950-03-23  2012-01-25  62.054945\n",
       "715537    1950-04-25  2012-04-02  62.151099\n",
       "\n",
       "[166200 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_users_cleaned = users_df[~users_df[\"Birthday\"].isna()]\n",
    "df_users_cleaned = df_users_cleaned[~df_users_cleaned[\"Joined\"].isna()]\n",
    "\n",
    "# Remove time stamp from date string\n",
    "df_users_cleaned[\"Birthday_Date\"] = df_users_cleaned[\"Birthday\"].str.slice(0,10)\n",
    "df_users_cleaned[\"Joined_Date\"] = df_users_cleaned[\"Joined\"].str.slice(0,10)\n",
    "\n",
    "# Convert string to date time object\n",
    "df_users_cleaned[\"Birthday_Date\"] = pd.to_datetime(df_users_cleaned[\"Birthday_Date\"], format=\"%Y-%m-%d\", errors = 'coerce')\n",
    "df_users_cleaned[\"Joined_Date\"] = pd.to_datetime(df_users_cleaned[\"Joined_Date\"], format=\"%Y-%m-%d\", errors = 'coerce')\n",
    "\n",
    "# Remove entries where joining date is before birthdate\n",
    "df_users_cleaned = df_users_cleaned[df_users_cleaned[\"Birthday_Date\"] < df_users_cleaned[\"Joined_Date\"]]\n",
    "\n",
    "# Remove entries where birthday is very very old\n",
    "df_users_cleaned = df_users_cleaned[df_users_cleaned[\"Birthday_Date\"] > pd.to_datetime(\"1950-01-01\",format=\"%Y-%m-%d\")]\n",
    "\n",
    "# Remove entries where age at joining is less than 5 years\n",
    "df_users_cleaned[\"Age_Join\"] = (df_users_cleaned[\"Joined_Date\"] - df_users_cleaned[\"Birthday_Date\"]) / np.timedelta64(52, 'W')\n",
    "df_users_cleaned = df_users_cleaned[df_users_cleaned[\"Age_Join\"]>5]\n",
    "\n",
    "df_users_cleaned[[\"Birthday_Date\",\"Joined_Date\", \"Age_Join\"]].sort_values(by=\"Age_Join\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning Anime Dataset\n",
    "\n",
    "The **Aired** attribute is very important for us. Our target is to extract information like how long an anime runs, is it still ongoing, how many episodes does it have. \n",
    "The aim is to extract start date and end date of an anime and add those 2 as new columns to the dataframe:\n",
    "    - Split the date string using the word **to** and strip white spaces\n",
    "    - convert both Start date and end date to datetime objects\n",
    "    - Inserted the new columns to the original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Aired</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>End Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apr 3, 1998 to Apr 24, 1999</td>\n",
       "      <td>1998-04-03</td>\n",
       "      <td>1999-04-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sep 1, 2001</td>\n",
       "      <td>2001-09-01</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apr 1, 1998 to Sep 30, 1998</td>\n",
       "      <td>1998-04-01</td>\n",
       "      <td>1998-09-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jul 3, 2002 to Dec 25, 2002</td>\n",
       "      <td>2002-07-03</td>\n",
       "      <td>2002-12-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sep 30, 2004 to Sep 29, 2005</td>\n",
       "      <td>2004-09-30</td>\n",
       "      <td>2005-09-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Aired Start Date   End Date\n",
       "0   Apr 3, 1998 to Apr 24, 1999 1998-04-03 1999-04-24\n",
       "1                   Sep 1, 2001 2001-09-01        NaT\n",
       "2   Apr 1, 1998 to Sep 30, 1998 1998-04-01 1998-09-30\n",
       "3   Jul 3, 2002 to Dec 25, 2002 2002-07-03 2002-12-25\n",
       "4  Sep 30, 2004 to Sep 29, 2005 2004-09-30 2005-09-29"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the date string using the word **to**\n",
    "aired = anime_df['Aired'].str.split('to', expand=True)\n",
    "# Then strip whitespaces\n",
    "aired[0] = aired[0].str.strip()\n",
    "aired[1] = aired[1].str.strip()\n",
    "\n",
    "# Finally convert both Start date and end date to datetime objects\n",
    "aired[0] = pd.to_datetime(aired[0], format='%b %d, %Y', errors='coerce')\n",
    "aired[1] = pd.to_datetime(aired[1], format='%b %d, %Y', errors='coerce')\n",
    "\n",
    "# Rename the clomns\n",
    "aired.rename(columns={0: 'Start Date', 1: 'End Date'}, inplace=True)\n",
    "\n",
    "# Inserted the new columns to the original dataframe\n",
    "anime_df.insert(10, 'Start Date', aired['Start Date'])\n",
    "anime_df.insert(11, 'End Date', aired['End Date'])\n",
    "\n",
    "anime_df[[\"Aired\", \"Start Date\", \"End Date\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim is to add a new cloumn named **Ongoing**. The way we do this is the aired column has format from start date to end date. The end date has ? for ongoing animes. Hence the rows having ? are tagged as ongoing animes\n",
    "This helps us in:\n",
    "    - Knowing if an anime is still ongoing\n",
    "    - Calculating number of episodes in an anime, for ongoing animes the dataset does not have number of episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24905 entries, 0 to 24904\n",
      "Data columns (total 27 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   anime_id      24905 non-null  int64         \n",
      " 1   Name          24905 non-null  object        \n",
      " 2   English name  24905 non-null  object        \n",
      " 3   Other name    24905 non-null  object        \n",
      " 4   Score         24905 non-null  object        \n",
      " 5   Genres        24905 non-null  object        \n",
      " 6   Synopsis      24905 non-null  object        \n",
      " 7   Type          24905 non-null  object        \n",
      " 8   Episodes      24905 non-null  object        \n",
      " 9   Aired         24905 non-null  object        \n",
      " 10  Start Date    20090 non-null  datetime64[ns]\n",
      " 11  End Date      9337 non-null   datetime64[ns]\n",
      " 12  Premiered     24905 non-null  object        \n",
      " 13  Status        24905 non-null  object        \n",
      " 14  Producers     24905 non-null  object        \n",
      " 15  Licensors     24905 non-null  object        \n",
      " 16  Studios       24905 non-null  object        \n",
      " 17  Source        24905 non-null  object        \n",
      " 18  Duration      24905 non-null  object        \n",
      " 19  Rating        24905 non-null  object        \n",
      " 20  Rank          24905 non-null  object        \n",
      " 21  Popularity    24905 non-null  int64         \n",
      " 22  Favorites     24905 non-null  int64         \n",
      " 23  Scored By     24905 non-null  object        \n",
      " 24  Members       24905 non-null  int64         \n",
      " 25  Image URL     24905 non-null  object        \n",
      " 26  Ongoing       24905 non-null  int64         \n",
      "dtypes: datetime64[ns](2), int64(5), object(20)\n",
      "memory usage: 5.1+ MB\n"
     ]
    }
   ],
   "source": [
    "def check(value):\n",
    "    return 1 if '?' in value else 0\n",
    "\n",
    "anime_df['Ongoing'] = anime_df['Aired'].apply(check)\n",
    "anime_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The episodes field is also very important for us. We can infer whether people like short animes or long animes based on number of episodes.\n",
    "However some records of our dataset have \"UNKNOWN\" in the episodes field, this is because the anime is currently running. Just for analysis purpose, we get the episode count till jan 01 2024, since each episode is released once in a week we divide the aired duration by 1 week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anime_id</th>\n",
       "      <th>Name</th>\n",
       "      <th>English name</th>\n",
       "      <th>Other name</th>\n",
       "      <th>Score</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Type</th>\n",
       "      <th>Episodes</th>\n",
       "      <th>Aired</th>\n",
       "      <th>...</th>\n",
       "      <th>Source</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Favorites</th>\n",
       "      <th>Scored By</th>\n",
       "      <th>Members</th>\n",
       "      <th>Image URL</th>\n",
       "      <th>Ongoing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [anime_id, Name, English name, Other name, Score, Genres, Synopsis, Type, Episodes, Aired, Start Date, End Date, Premiered, Status, Producers, Licensors, Studios, Source, Duration, Rating, Rank, Popularity, Favorites, Scored By, Members, Image URL, Ongoing]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 27 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index, row in anime_df.iterrows():\n",
    "    if row['Episodes'] == 'UNKNOWN':\n",
    "        anime_df.loc[index, 'Episodes'] = ((pd.to_datetime('Jan 01, 2024', format='%b %d, %Y') - row['Start Date']).days / 7)\n",
    "\n",
    "anime_df[anime_df['Episodes'] == 'UNKNOWN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we normalize episodes field so that we can bring it to a common scale for comparing between different animes\n",
    "\n",
    "We use MinMax normalization which shrinks the scale between 0 to 1.\n",
    "X_norm = (Xâˆ’min(X))/(max(X)âˆ’min(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.008181\n",
       "1        0.000000\n",
       "2        0.008181\n",
       "3        0.008181\n",
       "4        0.016688\n",
       "           ...   \n",
       "24900    0.004581\n",
       "24901    0.005563\n",
       "24902    0.004908\n",
       "24903    0.000000\n",
       "24904    0.000000\n",
       "Name: Episodes, Length: 24905, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime_df['Episodes'] = anime_df['Episodes'].astype(float)\n",
    "anime_df['Episodes'] = (anime_df['Episodes'] - anime_df['Episodes'].min()) / (anime_df['Episodes'].max() - anime_df['Episodes'].min())\n",
    "anime_df['Episodes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning User Details for Location of User\n",
    "\n",
    "The Location data is very unstructured, some have country name, some have country suffix, some have name of state and so on. We try to fetch the country name from this in multiple ways.\n",
    "\n",
    "1. We get the list of current countries and country codes using an API and then match the value in location column if it contains the code or country name.\n",
    "2. For US states, we map all us states to USA country and then check the location field for these states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import collections\n",
    "\n",
    "url = 'https://restcountries.com/v3.1/all'\n",
    "response = requests.get(url)\n",
    "countries = collections.defaultdict(str)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    response_body = response.json()\n",
    "\n",
    "    for i in range(len(response_body)):\n",
    "        common = response_body[i]['name']['common']\n",
    "        official = response_body[i]['name']['official']\n",
    "\n",
    "        countries[common] = common\n",
    "\n",
    "        if 'nativeNames' in response_body[i]:\n",
    "            native_names = response_body[i]['name']['nativeName']\n",
    "\n",
    "            for key, val in native_names.items():\n",
    "                countries[val['common']] = common\n",
    "                countries[val['official']] = common\n",
    "\n",
    "        if 'translations' in response_body[i]:\n",
    "            translations = response_body[i]['translations']\n",
    "\n",
    "            for key, val in translations.items():\n",
    "                countries[val['common']] = common\n",
    "                countries[val['official']] = common\n",
    "else:\n",
    "    print(\"Fail\")\n",
    "\n",
    "us_states = [\n",
    "    'Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut', 'Delaware', 'Florida', 'Georgia',\n",
    "    'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland',\n",
    "    'Massachusetts', 'Michigan', 'Minnesota', 'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire', 'New Jersey',\n",
    "    'New Mexico', 'New York', 'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania', 'Rhode Island', 'South Carolina',\n",
    "    'South Dakota', 'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington', 'West Virginia', 'Wisconsin', 'Wyoming'\n",
    "]\n",
    "\n",
    "for state in us_states:\n",
    "    countries[state] = 'United States'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82759\n"
     ]
    }
   ],
   "source": [
    "for index, row in users_df.iterrows():\n",
    "\n",
    "    location = row['Location']\n",
    "    \n",
    "    # To replace row whose type is not string with an empty string\n",
    "    if type(location) != str:\n",
    "        location = \"\"\n",
    "\n",
    "    location_splited = location.split(\",\")\n",
    "    is_valid_country = False\n",
    "\n",
    "    for splited_str in location_splited:\n",
    "        splited_str = splited_str.strip()\n",
    "\n",
    "        if splited_str in countries:\n",
    "            users_df.at[index, 'Location'] = countries[splited_str]\n",
    "            is_valid_country = True\n",
    "\n",
    "    if not is_valid_country:\n",
    "        users_df.at[index, 'Location'] = None\n",
    "\n",
    "print(users_df['Location'].notna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean User Details to trim number of users\n",
    "\n",
    "We trim the rows from user details to contain details of only the users for whom we have the user score data. Because without user score we cannot link a user data to anime data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 264069 entries, 0 to 731289\n",
      "Data columns (total 16 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   Mal ID            264069 non-null  int64  \n",
      " 1   Username          264068 non-null  object \n",
      " 2   Gender            140554 non-null  object \n",
      " 3   Birthday          103198 non-null  object \n",
      " 4   Location          53217 non-null   object \n",
      " 5   Joined            264069 non-null  object \n",
      " 6   Days Watched      264067 non-null  float64\n",
      " 7   Mean Score        264067 non-null  float64\n",
      " 8   Watching          264067 non-null  float64\n",
      " 9   Completed         264067 non-null  float64\n",
      " 10  On Hold           264067 non-null  float64\n",
      " 11  Dropped           264067 non-null  float64\n",
      " 12  Plan to Watch     264067 non-null  float64\n",
      " 13  Total Entries     264067 non-null  float64\n",
      " 14  Rewatched         264067 non-null  float64\n",
      " 15  Episodes Watched  264067 non-null  float64\n",
      "dtypes: float64(10), int64(1), object(5)\n",
      "memory usage: 34.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "common_users = pd.merge(user_score_df, users_df, left_on=['user_id', 'Username'], right_on=['Mal ID', 'Username'], how='inner')\n",
    "\n",
    "\n",
    "users_df = users_df[users_df.set_index(['Mal ID', 'Username']).index.isin(common_users.set_index(['user_id', 'Username']).index)]\n",
    "\n",
    "print(users_df.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Genres:\n",
    "In anime dataset we have a few anime where the genre is \"UNKNOWN\". Currently we will exclude animes whose genre is \"UNKNOWN\" but later we want to look into getting genre for such anime using its synopsis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anime_id</th>\n",
       "      <th>Name</th>\n",
       "      <th>English name</th>\n",
       "      <th>Other name</th>\n",
       "      <th>Score</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Type</th>\n",
       "      <th>Episodes</th>\n",
       "      <th>Aired</th>\n",
       "      <th>...</th>\n",
       "      <th>Source</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Favorites</th>\n",
       "      <th>Scored By</th>\n",
       "      <th>Members</th>\n",
       "      <th>Image URL</th>\n",
       "      <th>Ongoing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [anime_id, Name, English name, Other name, Score, Genres, Synopsis, Type, Episodes, Aired, Start Date, End Date, Premiered, Status, Producers, Licensors, Studios, Source, Duration, Rating, Rank, Popularity, Favorites, Scored By, Members, Image URL, Ongoing]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 27 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime_df = anime_df[~anime_df[\"Genres\"].isna()]\n",
    "\n",
    "anime_df = anime_df[anime_df['Genres'] != 'UNKNOWN']\n",
    "anime_df[anime_df['Genres'] == 'UNKNOWN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing the cleaned datasets in a new directory called cleaned_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir cleaned_datasets\n",
    "anime_df.to_csv(\"cleaned_datasets/anime_dataset_cleaned.csv\")\n",
    "users_df.to_csv(\"cleaned_datasets/users_details_dataset_cleaned.csv\")\n",
    "user_score_df.to_csv(\"cleaned_datasets/user_scores_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
