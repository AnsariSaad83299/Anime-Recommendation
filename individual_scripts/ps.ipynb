{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "731290\n",
      "53286\n",
      "53285\n"
     ]
    }
   ],
   "source": [
    "user_detail_data = pd.read_csv('datasets/users-details-2023.csv')\n",
    "user_detail_df = pd.DataFrame(user_detail_data)\n",
    "locations = user_detail_df['Location']\n",
    "\n",
    "print(len(locations))\n",
    "print(len(locations.unique()))\n",
    "print(locations.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://restcountries.com/v3.1/all'\n",
    "response = requests.get(url)\n",
    "countries = collections.defaultdict(str)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    response_body = response.json()\n",
    "\n",
    "    for i in range(len(response_body)):\n",
    "        common = response_body[i]['name']['common']\n",
    "        official = response_body[i]['name']['official']\n",
    "\n",
    "        countries[common] = common\n",
    "\n",
    "        if 'nativeNames' in response_body[i]:\n",
    "            native_names = response_body[i]['name']['nativeName']\n",
    "\n",
    "            for key, val in native_names.items():\n",
    "                countries[val['common']] = common\n",
    "                countries[val['official']] = common\n",
    "\n",
    "        if 'translations' in response_body[i]:\n",
    "            translations = response_body[i]['translations']\n",
    "\n",
    "            for key, val in translations.items():\n",
    "                countries[val['common']] = common\n",
    "                countries[val['official']] = common\n",
    "else:\n",
    "    print(\"Fail\")\n",
    "\n",
    "us_states = [\n",
    "    'Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut', 'Delaware', 'Florida', 'Georgia',\n",
    "    'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland',\n",
    "    'Massachusetts', 'Michigan', 'Minnesota', 'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire', 'New Jersey',\n",
    "    'New Mexico', 'New York', 'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania', 'Rhode Island', 'South Carolina',\n",
    "    'South Dakota', 'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington', 'West Virginia', 'Wisconsin', 'Wyoming'\n",
    "]\n",
    "\n",
    "for state in us_states:\n",
    "    countries[state] = 'United States'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82759\n"
     ]
    }
   ],
   "source": [
    "for index, row in user_detail_df.iterrows():\n",
    "\n",
    "    location = row['Location']\n",
    "    \n",
    "    # To replace row whose type is not string with an empty string\n",
    "    if type(location) != str:\n",
    "        location = \"\"\n",
    "\n",
    "    location_splited = location.split(\",\")\n",
    "    is_valid_country = False\n",
    "\n",
    "    for splited_str in location_splited:\n",
    "        splited_str = splited_str.strip()\n",
    "\n",
    "        if splited_str in countries:\n",
    "            user_detail_df.at[index, 'Location'] = countries[splited_str]\n",
    "            is_valid_country = True\n",
    "\n",
    "    if not is_valid_country:\n",
    "        user_detail_df.at[index, 'Location'] = None\n",
    "\n",
    "print(locations.notna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          user_id    Username  anime_id             Anime Title  rating\n",
      "0               1       Xinil        21               One Piece       9\n",
      "1               1       Xinil        48             .hack//Sign       7\n",
      "2               1       Xinil       320                  A Kite       5\n",
      "3               1       Xinil        49        Aa! Megami-sama!       8\n",
      "4               1       Xinil       304  Aa! Megami-sama! Movie       8\n",
      "...           ...         ...       ...                     ...     ...\n",
      "24325186  1291087   Oblongata     10611                    R-15       3\n",
      "24325187  1291087   Oblongata       174            Tenjou Tenge       6\n",
      "24325188  1291097  JuunanaSai      1535              Death Note       9\n",
      "24325189  1291097  JuunanaSai       226              Elfen Lied      10\n",
      "24325190  1291097  JuunanaSai      8425                  Gosick      10\n",
      "\n",
      "[23803779 rows x 5 columns]\n",
      "         Mal ID    Username  Gender                   Birthday       Location  \\\n",
      "0             1       Xinil    Male  1985-03-04T00:00:00+00:00  United States   \n",
      "2             4     Crystal  Female                        NaN      Australia   \n",
      "3             9      Arcane     NaN                        NaN           None   \n",
      "5            20      vondur    Male  1988-01-25T00:00:00+00:00         Norway   \n",
      "6            23       Amuro     NaN  1988-02-22T00:00:00+00:00         Canada   \n",
      "...         ...         ...     ...                        ...            ...   \n",
      "731280  1291057    imjustjk    Male  1997-12-24T00:00:00+00:00  United States   \n",
      "731284  1291079      Dybido    Male                        NaN           None   \n",
      "731286  1291085  alenrobnik     NaN                        NaN           None   \n",
      "731287  1291087   Oblongata     NaN  1993-01-30T00:00:00+00:00           None   \n",
      "731289  1291097  JuunanaSai  Female                        NaN           None   \n",
      "\n",
      "                           Joined  Days Watched  Mean Score  Watching  \\\n",
      "0       2004-11-05T00:00:00+00:00         142.3        7.37       1.0   \n",
      "2       2004-11-13T00:00:00+00:00         212.8        6.68      16.0   \n",
      "3       2004-12-05T00:00:00+00:00          30.0        7.71       5.0   \n",
      "5       2005-01-05T00:00:00+00:00          73.1        8.06      11.0   \n",
      "6       2005-01-23T00:00:00+00:00         142.5        7.41      20.0   \n",
      "...                           ...           ...         ...       ...   \n",
      "731280  2012-05-06T00:00:00+00:00         101.9        7.00       3.0   \n",
      "731284  2012-05-06T00:00:00+00:00          41.0        8.48       2.0   \n",
      "731286  2012-05-06T00:00:00+00:00          21.4        8.22      16.0   \n",
      "731287  2012-05-06T00:00:00+00:00          51.3        7.53      38.0   \n",
      "731289  2012-05-06T00:00:00+00:00           3.7        9.67       1.0   \n",
      "\n",
      "        Completed  On Hold  Dropped  Plan to Watch  Total Entries  Rewatched  \\\n",
      "0           233.0      8.0     93.0           64.0          399.0       60.0   \n",
      "2           636.0    303.0      0.0           45.0         1000.0       10.0   \n",
      "3            54.0      4.0      3.0            0.0           66.0        0.0   \n",
      "5            94.0     11.0      2.0           20.0          138.0        7.0   \n",
      "6           298.0      5.0     19.0           50.0          392.0        0.0   \n",
      "...           ...      ...      ...            ...            ...        ...   \n",
      "731280      181.0      5.0     19.0           34.0          242.0       19.0   \n",
      "731284       88.0      7.0      5.0           33.0          135.0        0.0   \n",
      "731286       58.0      9.0      1.0           42.0          126.0        0.0   \n",
      "731287      175.0      0.0      9.0          211.0          433.0        2.0   \n",
      "731289       11.0      0.0      0.0            2.0           14.0        0.0   \n",
      "\n",
      "        Episodes Watched  \n",
      "0                 8458.0  \n",
      "2                12781.0  \n",
      "3                 1817.0  \n",
      "5                 4374.0  \n",
      "6                 8565.0  \n",
      "...                  ...  \n",
      "731280            7015.0  \n",
      "731284            3317.0  \n",
      "731286            1239.0  \n",
      "731287            3010.0  \n",
      "731289             222.0  \n",
      "\n",
      "[264069 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "user_score_data = pd.read_csv('datasets/users-score-2023.csv')\n",
    "user_score_df = pd.DataFrame(user_score_data)\n",
    "common_users = pd.merge(user_score_df, user_detail_df, left_on=['user_id', 'Username'], right_on=['Mal ID', 'Username'], how='inner')\n",
    "\n",
    "user_score_df = user_score_df[user_score_df.set_index(['user_id', 'Username']).index.isin(common_users.set_index(['user_id', 'Username']).index)]\n",
    "user_detail_df = user_detail_df[user_detail_df.set_index(['Mal ID', 'Username']).index.isin(common_users.set_index(['user_id', 'Username']).index)]\n",
    "\n",
    "print(user_score_df)\n",
    "print(user_detail_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
